{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Neo4jVector\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        layout=\"wide\",\n",
    "        page_title=\"Graphy v1\",\n",
    "        page_icon=\":graph:\"\n",
    "    )\n",
    "    st.sidebar.image('logo.png', use_column_width=True) \n",
    "    with st.sidebar.expander(\"Expand Me\"):\n",
    "        st.markdown(\"\"\"\n",
    "    This application allows you to upload a PDF file, extract its content into a Neo4j graph database, and perform queries using natural language.\n",
    "    It leverages LangChain and OpenAI's GPT models to generate Cypher queries that interact with the Neo4j database in real-time.\n",
    "    \"\"\")\n",
    "    st.title(\"Graphy: Realtime GraphRAG App\")\n",
    "\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Get credentials from environment variables\n",
    "    api_key = os.getenv(\"API_KEY\")\n",
    "    embed_model = os.getenv(\"EMBED_MODEL\")\n",
    "    model= os.getenv(\"MODEL\")\n",
    "    organization = os.getenv(\"ORGANIZATION\")\n",
    "    anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    anthropic_model = os.getenv(\"MODEL_NAME\")\n",
    "    \n",
    "    embed = OpenAIEmbeddings(\n",
    "       api_key=api_key,\n",
    "       model=embed_model,\n",
    "       organization=organization)\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=api_key,\n",
    "        # model=model,\n",
    "        organization=organization, \n",
    "        temperature=0)\n",
    "    \n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    neo4j_url = os.getenv('NEO4J_URL')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "    if not all([openai_api_key, neo4j_url, neo4j_username, neo4j_password]):\n",
    "        st.error(\"Missing required environment variables. Please check your .env file.\")\n",
    "        return\n",
    "\n",
    "    # Initialize OpenAI components\n",
    "    if 'embeddings' not in st.session_state:\n",
    "        os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "        embeddings = embed\n",
    "        llm = llm # Use model that supports function calling\n",
    "        st.session_state['embeddings'] = embeddings\n",
    "        st.session_state['llm'] = llm\n",
    "    else:\n",
    "        embeddings = st.session_state['embeddings']\n",
    "        llm = st.session_state['llm']\n",
    "\n",
    "    # Initialize Neo4j connection\n",
    "    if 'neo4j_connected' not in st.session_state:\n",
    "        try:\n",
    "            graph = Neo4jGraph(\n",
    "                url=neo4j_url, \n",
    "                username=neo4j_username, \n",
    "                password=neo4j_password\n",
    "            )\n",
    "            st.session_state['graph'] = graph\n",
    "            st.session_state['neo4j_connected'] = True\n",
    "            st.sidebar.success(\"Connected to Neo4j database.\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Failed to connect to Neo4j: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        graph = st.session_state['graph']\n",
    "\n",
    "    # File uploader\n",
    "    uploaded_file = st.file_uploader(\"Please select a PDF file.\", type=\"pdf\")\n",
    "\n",
    "    if uploaded_file is not None and 'qa' not in st.session_state:\n",
    "        with st.spinner(\"Processing the PDF...\"):\n",
    "            # Save uploaded file to temporary file\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
    "                tmp_file.write(uploaded_file.read())\n",
    "                tmp_file_path = tmp_file.name\n",
    "\n",
    "            # Load and split the PDF\n",
    "            loader = PyPDFLoader(tmp_file_path)\n",
    "            pages = loader.load_and_split()\n",
    "\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40)\n",
    "            docs = text_splitter.split_documents(pages)\n",
    "\n",
    "            lc_docs = []\n",
    "            for doc in docs:\n",
    "                lc_docs.append(Document(page_content=doc.page_content.replace(\"\\n\", \"\"), \n",
    "                metadata={'source': uploaded_file.name}))\n",
    "\n",
    "            # Clear the graph database\n",
    "            cypher = \"\"\"\n",
    "              MATCH (n)\n",
    "              DETACH DELETE n;\n",
    "            \"\"\"\n",
    "            graph.query(cypher)\n",
    "\n",
    "            # Define allowed nodes and relationships\n",
    "            allowed_nodes = [\"Patient\", \"Disease\", \"Medication\", \"Test\", \"Symptom\", \"Doctor\"]\n",
    "            allowed_relationships = [\"HAS_DISEASE\", \"TAKES_MEDICATION\", \"UNDERWENT_TEST\", \"HAS_SYMPTOM\", \"TREATED_BY\"]\n",
    "\n",
    "            # Transform documents into graph documents\n",
    "            transformer = LLMGraphTransformer(\n",
    "                llm=llm,\n",
    "                allowed_nodes=allowed_nodes,\n",
    "                allowed_relationships=allowed_relationships,\n",
    "                node_properties=False, \n",
    "                relationship_properties=False\n",
    "            ) \n",
    "\n",
    "            graph_documents = transformer.convert_to_graph_documents(lc_docs)\n",
    "            graph.add_graph_documents(graph_documents, include_source=True)\n",
    "\n",
    "            # Create vector index\n",
    "            index = Neo4jVector.from_existing_graph(\n",
    "                embedding=embeddings,\n",
    "                url=neo4j_url,\n",
    "                username=neo4j_username,\n",
    "                password=neo4j_password,\n",
    "                database=\"neo4j\",\n",
    "                node_label=\"Patient\",\n",
    "                text_node_properties=[\"id\", \"text\"], \n",
    "                embedding_node_property=\"embedding\", \n",
    "                index_name=\"vector_index\", \n",
    "                keyword_index_name=\"entity_index\", \n",
    "                search_type=\"hybrid\" \n",
    "            )\n",
    "\n",
    "            st.success(f\"{uploaded_file.name} preparation is complete.\")\n",
    "\n",
    "            # Retrieve the graph schema\n",
    "            schema = graph.get_schema\n",
    "\n",
    "            # Set up the QA chain\n",
    "            template = \"\"\"\n",
    "            Task: Generate a Cypher statement to query the graph database.\n",
    "\n",
    "            Instructions:\n",
    "            Use only relationship types and properties provided in schema.\n",
    "            Do not use other relationship types or properties that are not provided.\n",
    "\n",
    "            schema:\n",
    "            {schema}\n",
    "\n",
    "            Note: Do not include explanations or apologies in your answers.\n",
    "            Do not answer questions that ask anything other than creating Cypher statements.\n",
    "            Do not include any text other than generated Cypher statements.\n",
    "\n",
    "            Question: {question}\"\"\" \n",
    "\n",
    "            question_prompt = PromptTemplate(\n",
    "                template=template, \n",
    "                input_variables=[\"schema\", \"question\"] \n",
    "            )\n",
    "\n",
    "            qa = GraphCypherQAChain.from_llm(\n",
    "                llm=llm,\n",
    "                graph=graph,\n",
    "                cypher_prompt=question_prompt,\n",
    "                verbose=True,\n",
    "                allow_dangerous_requests=True\n",
    "            )\n",
    "            st.session_state['qa'] = qa\n",
    "\n",
    "    if 'qa' in st.session_state:\n",
    "        st.subheader(\"Ask a Question\")\n",
    "        with st.form(key='question_form'):\n",
    "            question = st.text_input(\"Enter your question:\")\n",
    "            submit_button = st.form_submit_button(label='Submit')\n",
    "\n",
    "        if submit_button and question:\n",
    "            with st.spinner(\"Generating answer...\"):\n",
    "                res = st.session_state['qa'].invoke({\"query\": question})\n",
    "                st.write(\"\\n**Answer:**\\n\" + res['result'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
